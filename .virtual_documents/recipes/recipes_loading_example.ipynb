





import json as json
    
with open("recipes_data.json", "r") as read_file:
    recipes_data = json.load(read_file)


recipe_book_len = len(recipes_data)
str(recipe_book_len)











import pprint as pp
import requests
from config import CONFIG

host = CONFIG["host"]
port = CONFIG["port"]
user = CONFIG["user"]
password = CONFIG["password"]
#index_name = CONFIG["index_name"]
index_name = user





from opensearchpy import OpenSearch
from opensearchpy import helpers

# Create the client with SSL/TLS enabled, but hostname verification disabled.
client = OpenSearch(
    hosts = [{'host': host, 'port': port}],
    http_compress = True, # enables gzip compression for request bodies
    http_auth = (user, password),
    url_prefix = 'opensearch',
    use_ssl = True,
    verify_certs = False,
    ssl_assert_hostname = False,
    ssl_show_warn = False
)





resp = client.indices.close(index = index_name, timeout=600)
print(resp)





#be absolutely sure that you want to comment this line and actually delete the index!!!

if client.indices.exists(index=index_name):
    # Delete the index.
    response = client.indices.delete(
        index = index_name,
        timeout = 600
    )
    print('\nDeleting index:')
    print(response)






index_body = {
   "settings":{
      "index":{
         "number_of_replicas":0,
         "number_of_shards":4,
         "refresh_interval":"1s",
         "knn":"true"
      }
   },
   "mappings": {
        "properties": {
            "recipe_id": {"type": "keyword"},
            "title": {"type": "text"},
            "description": {"type": "text"},
            "time": {"type": "integer"},
            "difficulty": {"type": "keyword"},
            "ingredients": {
                "type": "nested",
                "properties": {
                    "text": {"type": "text"},
                    "name": {"type": "text"},
                    "quantity": {"type": "float"},
                    "unit": {"type": "keyword"}
                }
            },
            "instructions": {
                "type": "nested",
                "properties": {
                    "stepNumber": {"type": "integer"},
                    "text": {"type": "text"},
                    "durationSeconds": {"type": "integer"}
                }
            },
            "nutrients": {
                "type": "object",
                "properties": {
                    "calories": {
                        "type": "object",
                        "properties": {
                            "quantity": {"type": "float"},
                            "measurement": {"type": "keyword"}
                        }
                    },
                    "protein": {
                        "type": "object",
                        "properties": {
                            "quantity": {"type": "float"},
                            "measurement": {"type": "keyword"}
                        }
                    },
                    "fat": {
                        "type": "object",
                        "properties": {
                            "quantity": {"type": "float"},
                            "measurement": {"type": "keyword"}
                        }
                    },
                    "carbohydrates": {
                        "type": "object",
                        "properties": {
                            "quantity": {"type": "float"},
                            "measurement": {"type": "keyword"}
                        }
                    }
                }
            }
        }
    }
}

if client.indices.exists(index=index_name):
    print("Index already existed. Nothing to be done.")
else:        
    response = client.indices.create(index_name, body=index_body)
    print('\nCreating index:')
    print(response)






print('\n----------------------------------------------------------------------------------- INDEX SETTINGS')
settings = client.indices.get_settings(index = index_name)
pp.pprint(settings)

print('\n----------------------------------------------------------------------------------- INDEX MAPPINGS')
mappings = client.indices.get_mapping(index = index_name)
pp.pprint(mappings)

print('\n----------------------------------------------------------------------------------- INDEX #DOCs')
print(client.count(index = index_name))





#Comment line if you need to add to index

for recipe_id in recipes_data:
    
    # Extract and format ingredients data
    ingredients = []
    for ingredient_data in recipes_data[recipe_id]['ingredients']:
        ingredient = {
            "text": ingredient_data['displayText'],
            "name": ingredient_data['ingredient'],
            "quantity": ingredient_data['quantity'],
            "unit": ingredient_data['unit']
        }
        ingredients.append(ingredient)

    instructions = []
    for instruction_data in recipes_data[recipe_id]['instructions']:
        instruction = {
            "stepNumber": instruction_data['stepNumber'],
            "text": instruction_data['stepText'],
            "durationSeconds": instruction_data['stepDurationSeconds']
        }
        instructions.append(instruction)

    # Check if nutrients data is available
    nutrients_data = recipes_data[recipe_id].get('nutrition')
    if nutrients_data:
        # Check if nutrients are available
        nutrients = {}
        for nutrient_name in ['calories', 'carbohydrateContent', 'fatContent', 'proteinContent']:
            nutrient_data = nutrients_data.get('nutrients', {}).get(nutrient_name)
            if nutrient_data:
                nutrients[nutrient_name] = {
                    "quantity": nutrient_data.get('quantity'),
                    "unit": nutrient_data.get('measurement')
                }
    else:
        nutrients = None
    
    recipe = {
        "recipe_id": recipe_id,
        "title": recipes_data[recipe_id]['displayName'],
        "description": recipes_data[recipe_id]['description'],
        "difficulty": recipes_data[recipe_id]['difficultyLevel'],
        "ingredients": ingredients,
        "instructions": instructions,
        "nutrients": nutrients,  # Assign nutrients here
        "time": recipes_data[recipe_id]['totalTimeMinutes'],
    }

    # Add recipe to index
    result = client.index(index=index_name, id=int(recipe_id), body=recipe)

print('DONE')






comment this line if you need to delete the recipes

for i in range(0, recipe_book_len):
    response = client.delete(index=index_name, id=i)





def text_based_search(size, sources, query_txt, fields):
    query_bm25 = {
      'size': size,
      '_source': sources,
      'query': {
        'multi_match': {
          'query': query_txt,
          'fields': fields
        }
      }
    }
    return client.search(
        body = query_bm25,
        index = index_name
    )


result = text_based_search(recipe_book_len, ['recipe_id', 'title', 'description', 'ingredients'], 'chicken parmesan', ['title'])

print('\nSearch results:')
pp.pprint(result)









embedding_mappings = {
    "properties": {
        # "sentence_embedding":{
        #     "type":"knn_vector",
        #     "dimension": 768,
        #     "method":{
        #         "name":"hnsw",
        #         "space_type":"innerproduct",
        #         "engine":"faiss",
        #         "parameters":{
        #           "ef_construction":256,
        #           "m":48
        #         }
        #     }
        # },
        "title_embedding":{
            "type":"knn_vector",
            "dimension": 768,
            "method":{
                "name":"hnsw",
                "space_type":"innerproduct",
                "engine":"faiss",
                "parameters":{
                  "ef_construction":256,
                  "m":48
                }
            }
        },
        "description_embedding":{
            "type":"knn_vector",
            "dimension": 768,
            "method":{
                "name":"hnsw",
                "space_type":"innerproduct",
                "engine":"faiss",
                "parameters":{
                  "ef_construction":256,
                  "m":48
                }
            }
        },
        # "time_embedding":{
        #     "type":"knn_vector",
        #     "dimension": 768,
        #     "method":{
        #         "name":"hnsw",
        #         "space_type":"innerproduct",
        #         "engine":"faiss",
        #         "parameters":{
        #           "ef_construction":256,
        #           "m":48
        #         }
        #     }
        # },
        # "difficulty_embedding":{
        #     "type":"knn_vector",
        #     "dimension": 768,
        #     "method":{
        #         "name":"hnsw",
        #         "space_type":"innerproduct",
        #         "engine":"faiss",
        #         "parameters":{
        #           "ef_construction":256,
        #           "m":48
        #         }
        #     }
        # },
        # "ingredients_embedding":{
        #     "type":"knn_vector",
        #     "dimension": 768,
        #     "method":{
        #         "name":"hnsw",
        #         "space_type":"innerproduct",
        #         "engine":"faiss",
        #         "parameters":{
        #           "ef_construction":256,
        #           "m":48
        #         }
        #     }
        # },
        # "instructions_embedding":{
        #     "type":"knn_vector",
        #     "dimension": 768,
        #     "method":{
        #         "name":"hnsw",
        #         "space_type":"innerproduct",
        #         "engine":"faiss",
        #         "parameters":{
        #           "ef_construction":256,
        #           "m":48
        #         }
        #     }
        # },
        # "nutrients_embedding":{
        #     "type":"knn_vector",
        #     "dimension": 768,
        #     "method":{
        #         "name":"hnsw",
        #         "space_type":"innerproduct",
        #         "engine":"faiss",
        #         "parameters":{
        #           "ef_construction":256,
        #           "m":48
        #         }
        #     }
        # }
    }
}

client.indices.put_mapping(index=index_name, body=embedding_mappings)
mappings = client.indices.get_mapping(index = index_name)
pp.pprint(mappings)





from transformers import AutoTokenizer, AutoModel
import torch
import torch.nn.functional as F

#Mean Pooling - Take average of all tokens
def mean_pooling(model_output, attention_mask):
    token_embeddings = model_output.last_hidden_state #First element of model_output contains all token embeddings
    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()
    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)


#Encode text
def encode(texts):
    # Tokenize sentences
    encoded_input = tokenizer(texts, padding=True, truncation=True, return_tensors='pt')

    # Compute token embeddings
    with torch.no_grad():
        model_output = model(**encoded_input, return_dict=True)

    # Perform pooling
    embeddings = mean_pooling(model_output, encoded_input['attention_mask'])

    # Normalize embeddings
    embeddings = F.normalize(embeddings, p=2, dim=1)
    
    return embeddings


# Load model from HuggingFace Hub
tokenizer = AutoTokenizer.from_pretrained("sentence-transformers/msmarco-distilbert-base-v2")
model = AutoModel.from_pretrained("sentence-transformers/msmarco-distilbert-base-v2")

# docs = ["Around 9 Million people live in London", "London is known for its financial district"]
# doc_emb = encode(docs)
# print(len(doc_emb))

titles = []
descriptions = []
time = []
difficulty = []
ingredients = []
instructions = []
for recipe in recipes_data.values():
    titles.append(recipe["displayName"] if recipe["displayName"] is not None else 'None') 
    descriptions.append(recipe["description"] if recipe["description"] is not None else 'None')
    time.append(recipe["totalTimeMinutes"] if recipe["totalTimeMinutes"] is not None else 'None') 
    difficulty.append(recipe["difficultyLevel"] if recipe["difficultyLevel"] is not None else 'None')
    ingredients.append(recipe["ingredients"] if recipe["ingredients"] is not None else 'None')
    instructions.append(recipe["instructions"] if recipe["instructions"] is not None else 'None')
     
    
titles_emb = encode(titles)
descriptions_emb = encode(descriptions)
time_emb = encode(titles)
difficulty_emb = encode(titles)
ingredients_emb = encode(titles)
instructions_emb = encode(titles)

print(len(titles_emb))





#Comment line if you need to add to index

for recipe_id in recipes_data:
    # Extract and format ingredients data
    ingredients = []
    for ingredient_data in recipes_data[recipe_id]['ingredients']:
        ingredient = {
            "text": ingredient_data['displayText'],
            "name": ingredient_data['ingredient'],
            "quantity": ingredient_data['quantity'],
            "unit": ingredient_data['unit']
        }
        ingredients.append(ingredient)

    instructions = []
    for instruction_data in recipes_data[recipe_id]['instructions']:
        instruction = {
            "stepNumber": instruction_data['stepNumber'],
            "text": instruction_data['stepText'],
            "durationSeconds": instruction_data['stepDurationSeconds']
        }
        instructions.append(instruction)

    # Check if nutrients data is available
    nutrients_data = recipes_data[recipe_id].get('nutrition')
    if nutrients_data:
        # Check if nutrients are available
        nutrients = {}
        for nutrient_name in ['calories', 'carbohydrateContent', 'fatContent', 'proteinContent']:
            nutrient_data = nutrients_data.get('nutrients', {}).get(nutrient_name)
            if nutrient_data:
                nutrients[nutrient_name] = {
                    "quantity": nutrient_data.get('quantity'),
                    "unit": nutrient_data.get('measurement')
                }
    else:
        nutrients = None

    
    
    recipe = {
        "recipe_id": recipe_id,
        "title": recipes_data[recipe_id]['displayName'],
        "description": recipes_data[recipe_id]['description'],
        "difficulty": recipes_data[recipe_id]['difficultyLevel'],
        "ingredients": ingredients,
        "instructions": instructions,
        "nutrients": nutrients,
        "time": recipes_data[recipe_id]['totalTimeMinutes'],
        
        "title_embedding": titles_emb[int(recipe_id)].numpy(),
        "description_embedding": descriptions_emb[int(recipe_id)].numpy(),
        # "difficulty_embedding": recipes_emb[int(recipe_id)].numpy(),
        # "ingredients_embedding": recipes_emb[int(recipe_id)].numpy(),
        # "instructions_embedding": recipes_emb[int(recipe_id)].numpy(),
        # "nutrients_embedding": recipes_emb[int(recipe_id)].numpy(),
        # "time_embedding": recipes_emb[int(recipe_id)].numpy(),
    }

    # Add recipe to index
    result = client.index(index=index_name, id=int(recipe_id), body=recipe)

print('DONE')






# Compute the query embedding
query = "lemonade"
query_emb = encode(query)

query_denc = {
  'size': 5,
#  '_source': ['doc_id', 'contents', 'sentence_embedding'],
#  '_source': ['doc_id', 'contents'],
  '_source': ['title', 'description', 'ingredients'],
   "query": {
        "knn": {
          "title_embedding": {
            "vector": query_emb[0].numpy(),
            "k": 2
          }
        }
      }
}

response = client.search(
    body = query_denc,
    index = index_name
)

print('\nSearch results:')
pp.pprint(response)





def search_with_bool_filter(query_txt, sources, must_queries=None, should_queries=None, filters=None):
    query = {
        'size': 10,
        '_source': sources,
        'query': {
            'bool': {
                "must": must_queries if must_queries else [],
                "should": should_queries if should_queries else [],
                "filter": filters if filters else []
            }
        }
    }
    return client.search(
        body = query,
        index = index_name
    )

query_txt = 'What are the best chicken pasta dishes?'
must_queries = [{"match": {"title": "pasta"}}]
should_queries = [{'multi_match': {'query': query_txt, 'fields': ['ingredients']}}]
filters = [{"match": {"title": "chicken"}}]
result = search_with_bool_filter(query_txt, ['title', 'description', 'ingredients'], must_queries, should_queries, filters)

print('\nSearch results:')
pp.pprint(result)
